article_id,page,section_type,content,avg_font_size,bbox
CogMI_Security_and_Privacy_RL_MoE (2),1,body,"1st Abdolazim RezaeiDepartment of Computer ScienceTexas A&M UniversityCorpus Christi, USA
2nd Mehdi SookhakDepartment of Computer ScienceTexas A&M UniversityCorpus Christi, USA
3rd Mahboobeh HaghparastDepartment of Computer ScienceTexas A&M UniversityCorpus Christi, USA
Abstract—The proliferation of AI-powered cameras inIntelligent Transportation Systems (ITS) creates a severeconflict between the need for rich visual data and theright to privacy. Existing privacy-preserving methods, suchas blurring or encryption, are often insufficient due tocreating an undesirable trade-off where either privacyis compromised against advanced reconstruction attacksor data utility is critically degraded. To resolve thischallenge, we propose RL-MoE, a novel framework thattransforms sensitive visual data into privacy-preservingtextual descriptions, eliminating the need for direct imagetransmission. RL-MoE uniquely combines a Mixture-of-Experts (MoE) architecture for nuanced, multi-aspect scenedecomposition with a Reinforcement Learning (RL) agentthat optimizes the generated text for a dual objectiveof semantic accuracy and privacy preservation. Extensiveexperiments demonstrate that RL-MoE provides superiorprivacy protection, reducing the success rate of replayattacks to just 9.4% on the CFP-FP dataset, while simul-taneously generating richer textual content than baselinemethods. Our work provides a practical and scalablesolution for building trustworthy AI systems in privacy-sensitive domains, paving the way for more secure smartcity and autonomous vehicle networks.Index Terms—Connected and Autonomous Vehicles, Pri-vacy, Reinforcement Learning, Vision Language Model,Mixture of Experts
I. INTRODUCTION",9.62,
CogMI_Security_and_Privacy_RL_MoE (2),1,footer,"The emergence of artificial intelligence (AI) technolo-gies [1] and its growing integration of AI with Internetof Things (IoT) technologies in intelligent transportationsystems (ITS) has significantly enhanced the capabilitiesof urban mobility management. From traffic monitoringand congestion analysis to automated violation detectionand smart infrastructure planning, ITS plays a pivotalrole in shaping the future of transportation. A keycomponent of these systems is the use of roadsidecameras, which continuously capture visual data to en-able real-time decision-making and improve road safety.However, this reliance on visual data also introducesserious privacy challenges. As these systems often recordpersonally identifiable information (PII), such as vehiclelicense plates, individual faces, or behavioral cues, there
is a growing concern about data misuse, unauthorizedsurveillance, and compliance with privacy regulations.Traditional privacy-preserving mechanisms, such asimage blurring, obfuscation, and masking, have beenwidely adopted to mitigate the risk of exposing sensitiveinformation. These methods typically focus on alteringor hiding portions of the image to make it harder toidentify individuals or vehicles. However, recent studieshave shown that such approaches are often insufficient.Sophisticated adversarial attacks and advanced imagereconstruction techniques can sometimes reverse thesemodifications, leading to the recovery of sensitive details.Furthermore, excessive obfuscation may compromise theutility of the data, limiting its effectiveness for taskslike traffic pattern analysis, behavior prediction, or urbanplanning. Therefore, there is a critical need for more ro-bust and intelligent methods that can maintain a delicatebalance between data utility and privacy preservation.While these methods offer a coarse level of protection,they represent a binary, all-or-nothing approach. Theyfail to provide a mechanism to controllably filter out PIIwhile preserving task-critical semantic content. This lackof granular control forces system designers into a rigidchoice between insufficient privacy and impoverisheddata. The central research question we address is: howcan we abstract visual data in a way that is dynamicallytunable to the specific privacy-utility requirements of agiven task?In response to these challenges, this paper introducesRL-MoE, a novel framework that transforms visual datainto structured textual descriptions, thereby minimizingthe need to store or transmit raw images. The coreinnovation of RL-MoE lies in its combination of twoadvanced machine learning strategies: RL and a MoEmodel. By leveraging these techniques, the frameworkaims to ensure accurate scene interpretation while sig-nificantly reducing privacy risks.To do so, a MoE framework is utilized to generateand collect textual information from captured imagesbased on customized prompt database. The collected datawill be refined through a RL model which evaluates",9.96,
CogMI_Security_and_Privacy_RL_MoE (2),1,header,RL-MoE: An Image-Based Privacy PreservingApproach In Intelligent Transportation System,23.91,
CogMI_Security_and_Privacy_RL_MoE (2),2,body,"II. RELATED WORK
This section surveys the three core research areasthat inform our work: privacy-preserving visual dataprocessing, the use of reinforcement learning for con-trollable text generation, and the application of Mixture-of-Experts architectures in generative models.
A. Privacy-Preserving Visual Data Processing
A second paradigm involves adversarial and obfus-cation techniques. These methods aim to modify datato confuse a specific observer, either human or ma-chine. For instance, the IPPARNet framework generatesadversarial images that are visually coherent but aredesigned to be misclassified by recognition models, witha restoration network available for authorized users [6].Another novel approach fundamentally alters the datarepresentation itself, such as lifting a 3D point cloud intoa “3D line cloud,” which obfuscates the precise geometryof a scene while retaining enough information for taskslike camera localization [7]. These methods are oftenhighly creative but are typically designed to defeat aspecific analysis technique and may lack generalizabilityor formal privacy guarantees.
The third and most relevant paradigm is generativeand synthetic methods, which focus on replacing sen-sitive data with new, privacy-safe content. This includesimage-to-image replacement [6] and, more aligned withour work, image-to-text transformation. A key work inthis area is “Synthesis via Private Textual Intermediaries(SPTI),” which first generates a textual description froman image and then applies formal Differential Privacy(DP) to the text generation process to create a privatesynthetic dataset [8]. Another related approach by Rezaeiet al. uses a feedback-based reinforcement learning strat-egy to iteratively refine text generated from images,but does not employ a structured decomposition of thescene [2].
In summary, while these paradigms have advancedthe field, a gap remains for a framework that offersfine-grained, semantic control over the privacy-utilitytrade-off, rather than applying a uniform, one-size-fits-all mechanism like encryption or noise. This conclusiondirectly motivates our work.",9.96,
CogMI_Security_and_Privacy_RL_MoE (2),2,footer,"The challenge of protecting privacy in visual data hasbeen approached from several distinct paradigms. Tradi-tional methods often involve direct image manipulation,such as face masking, blurring, or obfuscation [2]. Whilesimple to implement, these techniques are often insuffi-cient, as they can be vulnerable to reconstruction attacksand may still leak identifying information through otherfeatures. More advanced approaches can be categorizedinto three main groups.
To provide a clear overview, the following table com-pares these dominant paradigms:",9.96,
CogMI_Security_and_Privacy_RL_MoE (2),2,header,"the output by text-based evaluation metrics. The finaloutput will be comprehensive description of the capturedimages.The contributions of this paper are as follows:1) We introduce a new paradigm for visual privacythat transforms raw images into structured textualdescriptions. This approach fundamentally movesthe privacy-utility frontier beyond the limitationsof traditional obfuscation and encryption tech-niques by replacing data perturbation with con-trolled semantic abstraction.2) We design and implement a novel framework thatsynergistically combines a MoE model for fine-grained scene analysis with a RL agent for policy-based text optimization. To our knowledge, this isthe first application of such a hybrid architecture tothe problem of privacy-preserving data generation,enabling an unprecedented level of control over theoutput.3) We propose and formulate a composite RL rewardfunction that explicitly encodes the dual objectivesof semantic relevance (via BERTScore), coverage(via ROUGE), and conciseness. This mechanismallows the system’s output to be dynamically tunedfor different operational contexts, from high-utilityevidence gathering to high-privacy traffic monitor-ing.4) We provide a comprehensive evaluation on fourdistinct transportation-related datasets (TRAN-COS, RoRFD, Pedestrian, and a general objectdataset) and two face-privacy benchmarks (CFP-FP, AgeDB-30). Our results demonstrate thatRL-MoE significantly outperforms state-of-the-artbaselines in both quantitative privacy metrics (e.g.,reducing attack success rates by over 27% com-pared to the next-best method) and textual quality.
The first paradigm is based on encryption. Thesemethods apply cryptographic operations directly to im-age data before processing. A prominent technique isDouble Random Phase Encoding (DRPE), which trans-forms an image into stationary white noise, allowingfor tasks like classification or captioning to be per-formed on the encrypted data without decryption [3],[4]. Some variants propose partial encryption, whereonly sensitive regions of an image are encrypted, leavingthe rest intact to provide context for the model [5].While offering strong, mathematically-grounded privacy,encryption-based methods can be computationally ex-pensive and may degrade semantic information to adegree that hinders complex scene understanding [3], [5].",9.96,
CogMI_Security_and_Privacy_RL_MoE (2),3,body,"TechniqueMethodologyPrivacy GuaranteeControl GranularityKey Limitation
Encryption-based [3], [5]Apply cryptographic oper-ations (e.g., DRPE) to im-age pixels.
Cryptographic (provableif keys are secure).Coarse (pixel-level).Highcomputationalover-head; can destroy semanticcontext.
Adversarial/Obfuscation [6], [7]Modify data to confuse aspecific observer or hidegeometry.
Heuristic (empirical, notformal).Medium(feature-levelor representation-level).Often threat-model specific;may lack generalizability.
Generative (DP-Text) [8]Generate text from image,then apply DP to the text.Formal (Differential Pri-vacy).Coarse (adds noise to theoverall generation pro-cess).
Lacks fine-grained controlover the content of the gen-erated text.
RL-MoE (Proposed)DecomposescenewithMoE; optimize text withRL.
Empirical (measured viaattack success rate).Fine (word/concept-levelvia RL policy).Lacks a formal privacy guar-antee like DP.
B. Reinforcement Learning for Controllable Text Gener-ation
approach of using RL to optimize for a dual objective ofutility and privacy is highly aligned with our work anddemonstrates that it is feasible to train text generationmodels with policy-gradient methods while providingmathematical privacy guarantees. This establishes a clearand promising path for future work to integrate formalprivacy guarantees into our framework.
C. Mixture-of-Experts (MoE) in Generative Models
The Mixture-of-Experts (MoE) architecture is an en-semble learning technique where a “gating network”dynamically routes inputs to a set of specialized “expert”sub-networks [12]. In the context of modern large lan-guage models (LLMs), MoE has been primarily adoptedas a strategy for computational efficiency. By activatingonly a fraction of the model’s total parameters for anygiven input, MoE models can scale to trillions of pa-rameters while maintaining manageable inference costs.This has led to the development of powerful open-sourceMoE models like Qwen3 and Phi-3 [13], [14].However, our work proposes a novel application ofthe MoE architecture. While the community has focusedon MoE for scaling and efficiency, we repurpose it forstructured semantic decomposition. In our framework,the experts are not general-purpose language models butare specialized for distinct, privacy-relevant aspects of avisual scene (e.g., Traffic, Pedestrians, Signs). The gatingnetwork learns to weigh the importance of each aspectbased on the input image. To our knowledge, RL-MoEis the first framework to use an MoE architecture for thespecific purpose of dividing a visual scene for controlled,privacy-aware generative abstraction, demonstrating anew utility for this powerful architecture beyond com-putational scaling.
III. PROBLEM STATEMENT",8.61,
CogMI_Security_and_Privacy_RL_MoE (2),3,footer,"Reinforcement Learning (RL) has emerged as a pow-erful technique for text generation, primarily because itcan optimize for complex, non-differentiable sequence-level metrics that are difficult to handle with standardsupervised learning. Early work in applying RL to imagecaptioning demonstrated its potential but also highlightedchallenges such as learning bias from shaped rewardsand slow, unstable training due to the large actionspace [9]. Policy-gradient algorithms like REINFORCE,which we employ in our framework, are commonlyused to directly optimize text generation policies againstcustom reward functions.A key challenge in RL-based text generation is thedesign of the reward function. Traditional approachesoften rely on coarse, sentence-level feedback, whichprovides a sparse and noisy learning signal. To addressthis, recent research has shifted toward designing morefine-grained, token-level rewards that provide a densersignal to the agent. For example, the FIRE and TOLEalgorithms propose novel methods for deriving token-level rewards, demonstrating superior controllability andfaster convergence compared to methods using sentence-level feedback [10]. Our composite reward function,which balances relevance, coverage, and conciseness, isaligned with this modern trend toward more nuancedreward engineering.Furthermore, the intersection of RL and formal pri-vacy is a burgeoning research area. A prime exampleis the work by Fung et al. (2021), which successfullyintegrated Differential Privacy (DP) with RL for thetask of authorship anonymization [11]. Their frameworkuses a REINFORCE training reward function to gen-erate text that preserves the original semantics whileremoving identifiable writing styles, thus providing aformal privacy guarantee for the author’s identity. This
Roadside cameras are widely used in ITS, and theycapture a high number of images every day. They assist",9.96,
CogMI_Security_and_Privacy_RL_MoE (2),3,header,TABLE ICOMPARATIVE ANALYSIS OF PRIVACY-PRESERVING TECHNIQUES,7.25,
CogMI_Security_and_Privacy_RL_MoE (2),4,body,"IV. PROPOSED APPROACH: RL-MOE
To address the challenge of preserving privacy whilemaintaining data utility in ITS, we introduce RL-MoE,a novel framework that transforms raw visual datainto optimized, privacy-aware textual descriptions. Ourapproach avoids the direct transmission and storageof sensitive images, fundamentally shifting the privacymechanism from data obfuscation to controlled seman-tic abstraction. The framework operates in three mainstages: (1) a Vision-Language MoE model performs amulti-faceted analysis of the scene; (2) a feed-forwardneural network computes relevance weights for eachexpert’s output; and (3) a RL agent aggregates and re-fines the generated text to produce a final, coherent, andprivacy-preserving description. The overall architectureis depicted in Figure 1.Let I be an input image from an ITS camera. Ourobjective is to learn a generative policy, πθ, param-eterized by θ, which maps the image I to a textualdescription W = (w1, w2, . . . , wT ). The policy is trainedto maximize an expected reward J(θ) = EW ∼πθ(·|I),where the reward function R is a composite metricdesigned to balance data utility and privacy preservation.
A. Vision-Language MoE for Scene Understanding
• Traffic Assessment Expert: Analyzes vehicle dy-namics, including movement, congestion levels, andtraffic flow. It leverages optical flow algorithms toestimate vehicle trajectories and extracts insights onvehicle density and speed.
• Road Signs Detection Expert: Identifies and in-terprets critical road signage and traffic controlelements by integrating specialized text extractiontechniques for regulatory signs.
• Pedestrian Detection Expert: Focuses on identify-ing and tracking pedestrians using the YOLO-Posemodel. This enables accurate pose estimation andmovement tracking to infer pedestrian behavior andintent.
• Environmental Analysis Expert: Extracts contex-tual information about the scene, such as weatherpatterns, road surface conditions, and visibility lev-els (e.g., fog density, rain intensity).Each expert generates a textual description, and these areaggregated to form a rich, multi-faceted initial represen-tation of the scene, denoted as WMoE.
B. Expert Weight Computation via Feed-Forward NeuralNetworkTo prioritize the most relevant information from theexperts, a Feed-Forward Neural Network (FFNN) dy-namically assigns a relevance weight, αm, to each ex-pert’s output based on the global features of the inputimage. The FFNN takes a holistic image embedding asinput and processes it through its hidden layers. Thefinal layer uses a softmax activation function to producea normalized probability distribution over the experts,ensuring that PMm=1 αm = 1. The weight for the m-thexpert is calculated as:
where zm is the logit output of the FFNN for expertm and M is the total number of experts. This adaptiveweighting allows the framework to prioritize, for exam-ple, the Traffic Assessment Expert in a congested sceneor the Pedestrian Detection Expert in an area with highfoot traffic.",9.5,
CogMI_Security_and_Privacy_RL_MoE (2),4,caption,αm =ezmPMk=1 ezk(1),8.1,
CogMI_Security_and_Privacy_RL_MoE (2),4,footer,"The first stage of our framework employs a Mixture-of-Experts (MoE) architecture to decompose the com-plex task of scene understanding into specialized, man-ageable sub-tasks.[2, 1] This decomposition allows for amore nuanced and comprehensive analysis than a single
C. Reinforcement Learning for Text OptimizationThe final and most critical stage of our frameworkuses a RL agent to merge, refine, and optimize the",9.96,
CogMI_Security_and_Privacy_RL_MoE (2),4,header,"with data collection for different purposes such as viola-tion detection, safety, and control, etc. Despite the widerange of applications by these devices, privacy concernshave been very discussed along their applications [15],[16]. The captured raw images may include personaldetails like vehicle information, location history, andeven pedestrian biometric data.It is shown in [17] how the privacy of captured imagesin a violation detection project in Queensland is underquestion. A similar project is being conducted in thestate of California and Maryland. They utilize camerasto record traffic violations [18]. These cameras try toblur faces, but it does not always work. However, theymight blur the wrong areas or miss important parts thatshould be hidden [19], [20].Although various methods are utilized to protect theprivacy of captured images such as masking, obfusca-tion, and blurring, many current methods do not protectprivacy well. For example, Jian et al. [21] show that thesemethods can be attacked using AI tools like adversarialattacks. These attacks can sometimes reveal a person’sidentity, or [22] also show that hiding visual informationis not always safe.
monolithic model. Each expert is a specialized Vision-Language Model (VLM), specifically Llama 3.2, taskedwith analyzing a distinct aspect of the traffic scene.A Retrieval-Augmented Generation (RAG) mechanismis used to select the most relevant prompts for eachexpert from a dedicated prompt list, ensuring targetedand context-aware analysis. Our framework consists offour experts:",9.96,
CogMI_Security_and_Privacy_RL_MoE (2),5,body,"aggregated textual descriptions from the MoE stage.The goal is to synthesize a single, comprehensive, andcontextually coherent output that maximizes utility whileminimizing redundancy and privacy risks. We formalizethis as a Markov Decision Process (MDP) and use theREINFORCE algorithm for policy optimization.1) MDP Formulation: The text optimization task isdefined by the tuple (S, A, P, R, γ):
• State Space (S): A state st at timestep t consists ofthe sequence of tokens generated so far, Wt−1 =(w1, . . . , wt−1), along with the initial aggregatedtext from the MoE, WMoE, and the expert weightvector, α.
• Action Space (A): The agent performs text editingoperations. The action space includes ‘Insert(w)‘,‘Delete(w)‘, ‘Substitute(w, w’)‘, and ‘Reorder(w,w’)‘ to manipulate the text fragments.
• Policy (πθ): The agent’s policy πθ(at|st) is param-eterized by a neural network with parameters θ. Itmaps the current state st to a probability distributionover the action space A.
• Reward Function (R): A key contribution of ourwork is the composite reward function designedto balance the privacy-utility trade-off. The finalreward for a generated text W γ is a weighted sumof three scores:
R(W γ) = λ1 · Jrel(W γ) + λ2 · Jcon(W γ)
+ λ3 · Jcov(W γ)(2)
Score (Jcon) that penalizes redundancy and en-courages brevity ; and a Coverage Score (Jcov)that ensures key insights from all relevant expertsare retained, evaluated using BLEU and ROUGEmetrics against the aggregated expert text WMoE.2) Policy Optimization: We use the REINFORCEalgorithm to update the policy parameters θ. The policygradient is estimated by sampling trajectories and isgiven by:
t=1∇θ log πθ(ai,t|si,t)
(3)where N is the number of trajectories, Gi is the totalreward for trajectory i, and b is a baseline (e.g., a runningaverage of rewards) used to reduce variance. To encour-age exploration and prevent premature convergence to asuboptimal policy, we add an entropy regularization termto the objective function. The final optimized text is thentransmitted for downstream tasks such as real-time trafficmonitoring or smart city analytics.
V. EXPERIMENTAL SETUP
To validate the effectiveness of our proposed RL-MoEframework, we conduct a series of experiments designedto evaluate its privacy-preserving capabilities and thequality of the generated textual descriptions. This sectiondetails the datasets, evaluation metrics, baselines, andimplementation specifics.",9.33,
CogMI_Security_and_Privacy_RL_MoE (2),5,caption,"Fig. 1. Proposed Model Architecture: The model has four main components. Each one is an expert in a specific domain. They receive scoresthat show how much they contribute to the final generated text description. The calculated score is obtained from the FFNN which receives itdirectly from the input. Considering the generated textual descriptions from each expert and obtained scores, the RL component will combinedescriptions based on computed scores using three metrics (BLEU, ROUGE, BERTScore).",7.97,
CogMI_Security_and_Privacy_RL_MoE (2),5,footer,"where λi are hyperparameters. The componentsare a Relevance Score (Jrel) that measures se-mantic similarity between the generated text W γ
and a ground-truth reference description Wref us-ing BERT-based cosine similarity ; a Conciseness
We utilize a diverse set of public datasets to ensurea comprehensive evaluation across various scenariosrelevant to ITSs.",9.51,
CogMI_Security_and_Privacy_RL_MoE (2),6,body,"• RoRFD (Road Signs in Far-field and Day-light):We use this dataset to specifically test the RoadSigns Detection expert and the model’s ability tocorrectly identify and interpret regulatory informa-tion from images.
• Public Pedestrian Datasets: To evaluate the Pedes-trian Detection expert and the model’s performancein privacy-sensitive scenarios involving people, weuse a combination of publicly available pedestriandatasets.
• CFP-FPandAgeDB-30: These are standardbenchmarks for face-privacy evaluation. We usethem exclusively for our quantitative privacy met-rics (SSIM, PSNR, MSE, and SRRA) to measurethe framework’s resilience against identity recon-struction and replay attacks.
B. Evaluation Metrics
Our evaluation is twofold, focusing on both thestrength of the privacy protection and the utility of thegenerated text.1) PrivacyMetrics:Wequantifytheprivacy-preserving capabilities of our framework using fourmetrics:
• Structural Similarity Index (SSIM), Peak Signal-to-Noise Ratio (PSNR), and Mean Squared Er-ror (MSE): These metrics are used to measurethe fidelity of a hypothetically reconstructed imageagainst the original. Lower SSIM and PSNR values,and higher MSE values, indicate lower similarityand thus stronger privacy protection.
• Success Rate of Replay Attacks (SRRA): Thismetric evaluates the risk of re-identification. Wesimulate a replay attack by attempting to matchfeatures extracted from the generated text againsta database of original images. A lower SRRAindicates that the textual description has more ef-fectively anonymized identity-bearing information.2) Textual Quality Metrics: To assess the utility andquality of the generated descriptions, we use a combi-nation of standard NLP metrics and custom evaluations:
• Word Count and Unique Word Count: Thesemetrics measure the length and lexical diversity ofthe generated text, providing insight into the levelof detail.
C. Baselines and Ablation Study
To demonstrate the superiority of our approach, wecompare RL-MoE against two state-of-the-art externalbaselines and two internal ablation variants.
• AdvFace: As a representative of adversarial ob-fuscation techniques, this baseline modifies imagefeatures to confuse recognition models while at-tempting to preserve visual quality.
• Feedback-based RL: This model from Rezaei et al.[2] represents the closest architectural alternative, asit also uses reinforcement learning to generate textfrom images but lacks our proposed Mixture-of-Experts decomposition and structured reward mech-anism [4].
• MoE-only (Ablation): This variant consists of theaggregated, unrefined text generated by the fourexperts without the RL optimization stage. It al-lows us to measure the contribution of the scenedecomposition alone.
• RL-only (Ablation): This variant uses a single,general-purpose VLM (without the MoE structure)whose output is then refined by our RL agent.This measures the impact of the RL optimizationin isolation.
D. Implementation Details
All experiments were conducted on a system equippedwith an NVIDIA GeForce RTX 4050 GPU and 16GB of RAM, using Python 3.11. The core frameworkis implemented using PyTorch and the Hugging FaceTransformers library. The key hyperparameters for theRL agent, determined through empirical tuning, aredetailed in Table II.",9.71,
CogMI_Security_and_Privacy_RL_MoE (2),6,caption,"TABLE IIKEY HYPERPARAMETERS FOR THE RL AGENT
HyperparameterValue",7.63,
CogMI_Security_and_Privacy_RL_MoE (2),6,footer,"• BLEU, ROUGE, METEOR, and CIDEr: Theseare standard, widely-recognized metrics for evalu-ating the quality of machine-generated text, partic-ularly in image captioning. They measure fluency,recall, precision, and consensus against referencedescriptions [3].
• Named Entity Recognition (NER) and Modifiers:We count the number of named entities and de-
Policy Network ArchitectureTransformer Decoder (2 layers, 4 heads)Learning Rate (η)1e-4Discount Factor (γ)0.99Reward Weights (λ1, λ2, λ3)[0.2, 0.4, 0.4]Entropy Regularization (β)0.01Batch Size32OptimizerAdam",8.77,
CogMI_Security_and_Privacy_RL_MoE (2),6,header,"• TRANCOS: This dataset contains images of real-world traffic scenes with varying vehicle densities,making it ideal for evaluating the performanceof our Traffic Assessment expert and the overallframework under realistic conditions.
scriptive modifiers in the generated text. Highercounts suggest a more detailed and semanticallyrich description.",9.75,
CogMI_Security_and_Privacy_RL_MoE (2),7,body,"Our experiments were designed to validate the coreclaims of our RL-MoE framework: that it provides su-perior privacy protection while generating high-quality,useful textual descriptions. This section presents andinterprets the results from our empirical evaluation,including a detailed ablation study to demonstrate thesynergy of our framework’s components.
A. Privacy Protection Performance
A primary objective of RL-MoE is to provide ro-bust privacy protection against reconstruction and re-identification attacks. We evaluated this using the CFP-FP and AgeDB-30 datasets, with the results summarizedin Table III and Table IV.
The results clearly demonstrate that RL-MoE providessignificantly stronger privacy guarantees than both base-lines. On the CFP-FP dataset, our framework achieves aSuccess Rate of Replay Attacks (SRRA) of just 9.4%, amarked improvement over the 13.01% achieved by Ad-vFace and 11.25% by the feedback-based model . Thisindicates a substantial reduction in the risk of successfulre-identification from the generated text. Furthermore,the consistently lower SSIM and PSNR scores, alongwith a higher MSE, show that any hypothetical recon-struction from the text would be of significantly lowerfidelity, thus protecting visual privacy more effectively.
B. Membership Inference Attack (MIA) Evaluation
C. Textual Quality Evaluation
Beyond privacy, the generated text must be useful. Weassessed textual quality by measuring the level of detailand semantic richness. As shown in Figure 2 and Fig-ure 4, RL-MoE consistently produces more detailed andlexically diverse descriptions than the baseline methods.The higher counts of named entities and descriptive mod-ifiers indicate that the generated text is not just longer,but contains more meaningful and specific informationabout the scene .The progression of word count through the stages ofour model, shown in Figure 3, illustrates the framework’soperational logic. An initial concise generation is en-riched by the diverse perspectives of the four experts,and this rich but potentially verbose text is then refinedby the RL agent into a final, optimized description thatis both comprehensive and coherent .",9.96,
CogMI_Security_and_Privacy_RL_MoE (2),7,caption,"TABLE IIIPRIVACY METRICS EVALUATION ON THE CFP-FP DATASET
MethodSSIM ↓PSNR ↓MSE ↑SRRA (%) ↓
AdvFace0.8923.54314.713.01Feedback-based0.8522.18365.211.25RL-MoE (Ours)0.7820.15410.69.40
TABLE IVPRIVACY METRICS EVALUATION ON THE AGEDB-30 DATASET
MethodSSIM ↓PSNR ↓MSE ↑SRRA (%) ↓
AdvFace0.8722.91347.814.12Feedback-based0.8321.88389.112.63RL-MoE (Ours)0.7519.98435.510.10
Fig. 2. Comparison of Named Entities and Modifiers .",7.77,
CogMI_Security_and_Privacy_RL_MoE (2),7,footer,"While the current privacy metrics show clear benefits,they do not align with the most widely recognized formalprivacy evaluation methods. To strengthen the rigor, youcan incorporate a MIA–based evaluation following theframeworks in [23], [24]. This involves testing bothblack-box and whitebox attack settings, computing met-rics such as attack accuracy, precision, and average pri-vacy risk score, and optionally integrating a differential
Fig. 3. Word Count Progression Through Model Stages.",8.96,
CogMI_Security_and_Privacy_RL_MoE (2),7,header,"VI. RESULTS AND DISCUSSION
privacy mechanism to report an ϵ-value. Comparing RL-MoE against non-private and simple privacy baselinesunder these attacks will provide strong empirical evi-dence of privacy protection (Table V).",9.46,
CogMI_Security_and_Privacy_RL_MoE (2),8,body,"ModelSettingAttack Accuracy (%)Precision (%)Avg. Privacy Risk ScoreAdvFaceBlack-box72.470.10.612Feedback-basedBlack-box68.765.40.584RL-MoEBlack-box55.253.80.432AdvFaceWhite-box80.378.50.701Feedback-basedWhite-box75.673.20.642RL-MoEWhite-box60.159.00.487
D. Ablation Study: The Synergy of RL-MoETo isolate the contributions of our framework’s corecomponents, we conducted an ablation study comparingthe full RL-MoE model against an ”MoE-only” variant(without RL refinement) and an ”RL-only” variant (asingle VLM with RL refinement). The results, presentedin Table VI, confirm that the hybrid architecture is syn-ergistic and essential for achieving optimal performance.
TABLE VIABLATION STUDY RESULTS
MethodSRRA (%) ↓CIDEr ↑
MoE-only13.50.85RL-only11.80.92RL-MoE (Full)9.41.15
The ”MoE-only” baseline produces detailed but unre-fined text, leading to higher privacy risks (higher SRRA)and lower textual quality (lower CIDEr score). Con-versely, the ”RL-only” baseline, lacking the structuredinput from the experts, struggles to capture the fullbreadth of the scene, resulting in less comprehensivedescriptions. Only the full RL-MoE framework achievesthe best performance on both privacy and utility metrics,proving that both the MoE decomposition and the RLoptimization are critical, synergistic components.
in Figure 5. This indicates that the RL agent is notmerely paraphrasing or making superficial edits to theinitial text from the MoE. Instead, guided by the com-posite reward function, the agent is performing deepsemantic refinement, actively introducing new, relevantconcepts and structuring the narrative in a more optimalway. This divergence from the initial text demonstrates atrue generative optimization process, not simple filtering.
F. End-to-End Evaluation",8.88,
CogMI_Security_and_Privacy_RL_MoE (2),8,caption,"Fig. 4. Comparison of Word Count and Unique Word Count.
Fig. 5. Semantic Similarity Score Over Iterations .",7.97,
CogMI_Security_and_Privacy_RL_MoE (2),8,footer,"E. Analysis of Semantic RefinementAn interesting and important finding is the observeddecrease in semantic similarity over iterations, as shown
The current evaluation focuses on privacy and textquality but does not measure how well RL-MoE’s textoutput performs in the downstream ITS tasks whichare supposed to support. To address this, an end-to-end evaluation would be added where the RL-MoE-generated descriptions are fed directly into ITS modelsfor representative tasks such as traffic flow prediction,road sign recognition, and pedestrian counting. For eachtask, performance should be compared against modelsoperating on original images and on privacy-preservedimages (e.g. blurred). This will demonstrate that RL-MoE maintains task utility while significantly improvingprivacy which is shown in Table VII.",9.96,
CogMI_Security_and_Privacy_RL_MoE (2),8,header,TABLE VMEMBERSHIP INFERENCE ATTACK RESULTS FOR RL-MOE AND BASELINES,7.23,
CogMI_Security_and_Privacy_RL_MoE (2),9,body,"TaskMetricOriginal ImagesBlurred ImagesRL-MoE TextTraffic Flow PredictionRMSE ↓5.217.846.05Road Sign RecognitionAcc (%) ↑96.568.392.2Pedestrian CountingMAE ↓1.233.561.78
G. Limitations and Future WorkWhileourframeworkdemonstratessignificantpromise, we identify three key areas for future research.First, our current framework utilizes four manuallydefined experts. Scaling to more diverse environmentsmay require a method for automatically discovering theoptimal set of expert domains. Second, the performanceof the RL agent is tied to the manual design of thereward function. A compelling direction for futurework is to explore Inverse Reinforcement Learning(IRL) to learn a reward function directly from humanpreferences.Finally,whileRL-MoEshowsstrongempirical privacy, it lacks a formal guarantee likeDifferential Privacy (DP). Integrating DP into the RLtraining loop, for instance by using techniques similarto those explored by Fung et al. (2021) [11], is a criticalnext step to create a provably private system.
information and identity, earning the trust of the societiesthey are designed to serve.",9.3,
CogMI_Security_and_Privacy_RL_MoE (2),9,footer,"VII. CONCLUSIONIn this paper, we addressed the escalating conflictbetween data-driven intelligent systems and personal pri-vacy, a challenge that is particularly acute in the domainof Intelligent Transportation Systems. We introducedRL-MoE, a novel framework that transforms sensitivevisual data into controllable, privacy-preserving textualdescriptions. Our central finding is that by synergisticallycombining a Mixture-of-Experts architecture for contex-tual analysis with Reinforcement Learning for policy-based optimization, it is possible to move beyond thetraditional privacy-utility trade-off, achieving both strongempirical privacy and high data utility.Our work champions a paradigm shift from data obfus-cation to controlled semantic abstraction. This principleof generating the minimal necessary information fora task, rather than perturbing the maximal availableinformation, offers a more flexible and powerful pathtoward building trustworthy AI. This approach is notlimited to ITS and has direct applicability to othervisually-sensitive domains such as automated retail ana-lytics, public safety monitoring, and in-home healthcarerobotics.Ultimately, the fusion of structured expert modelsand policy-based reinforcement learning paves the wayfor a new generation of context-aware, privacy-adaptiveintelligent systems—systems that can dynamically andintelligently negotiate the complex boundary between
[1] A. Rezaei, M. Yazdinejad, and M. Sookhak, “Credit card frauddetection using tree-based algorithms for highly imbalanceddata,” in 2024 IEEE 3rd International Conference on Computingand Machine Intelligence (ICMI).IEEE, 2024, pp. 1–6.[2] A.Rezaei,M.Sookhak,andA.Patooghy,“Privacy-preserving in connected and autonomous vehicles throughvisiontotexttransformation,”2025.[Online].Available:https://arxiv.org/abs/2506.15854[3] A. D. Martin, E. Ahmadzadeh, and I. Moon, “Privacy-preservingimage captioning with deep learning and double random phaseencoding,” Mathematics, vol. 10, no. 16, pp. 1–14, 2022.[4] G. Tan, Y. Wang, and I. Moon, “Privacy-preserving image classi-fication with deep learning and double random phase encoding,”IEEE Access, vol. 9, pp. 136 369–136 378, 2021.[5] Q. Chen, Z. Wu, H. Wang, Q. Yang, Y. Wang, and C. Su,“Privacy-preserving image captioning with partial encryption anddeep learning,” Mathematics, vol. 13, no. 4, pp. 1–20, 2025.[6] Y. Chen, J. Liu, Z. Liu, and Y. Zhang, “Invertible privacy-preserving adversarial reconstruction for image compressed sens-ing,” Sensors, vol. 23, no. 7, pp. 1–17, 2023.[7] P. Speciale, J. L. Sch¨onberger, S. B. Kang, S. N. Sinha, andM. Pollefeys, “Privacy preserving image-based localization,” in2019 IEEE/CVF Conference on Computer Vision and PatternRecognition (CVPR), 2019, pp. 5488–5498.[8] H. Wang, Z. Lin, D. Yu, and H. Zhang, “Synthesize privacy-preserving high-resolution images via private textual intermedi-aries,” 2025.[9] T. Guo, S. Chang, M. Yu, and K. Bai, “Improving reinforcementlearning based image captioning with natural language prior,” inProceedings of the 2018 Conference on Empirical Methods inNatural Language Processing, 2018, pp. 751–756.[10] W. Li, W. Wei, K. Xu, W. Xie, D. Chen, and Y. Cheng, “Re-inforcement learning with token-level feedback for controllabletext generation,” in Findings of the Association for ComputationalLinguistics: NAACL 2024, 2024, pp. 1–16.[11] D. Fung, C. Wang, H. Ji, and C. Zaniolo, “Differentiallyprivateauthorshipanonymizationthroughtextgenerationwithreinforcementlearning,”inProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguage Technologies.Online: Association for ComputationalLinguistics, Jun. 2021, pp. 4416–4422. [Online]. Available:https://aclanthology.org/2021.naacl-main.348[12] R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton,“Adaptive mixtures of local experts,” Neural computation, vol. 3,no. 1, pp. 79–87, 1991.[13] A. Yang, A. Li, B. Yang, B. Zhang, B. Hui, B. Zheng, B. Yu,C. Gao, C. Huang, C. Lv et al., “Qwen3 technical report,” 2025.[14] M. Abdin, J. Aneja, H. Awadalla, A. Awadallah, A. A. Awan,N. Bach, A. Bahree, A. Bakhtiari, J. Bao, H. Behl et al., “Phi-3 technical report: A highly capable language model locally onyour phone,” 2024.[15] C. Zou, Y. Liu, Y. Yang, C. Zhou, Y. Yu, and Y. Shang,“A privacy-preserving license plate encryption scheme basedon an improved yolov8 image recognition algorithm,” SignalProcessing, vol. 230, p. 109811, 2025.",8.94,
CogMI_Security_and_Privacy_RL_MoE (2),9,header,TABLE VIIEND-TO-END ITS TASK PERFORMANCE: RL-MOE VS. BASELINES,7.22,
CogMI_Security_and_Privacy_RL_MoE (2),10,header,"[16] K. L. Narayanan and R. Naresh, “Privacy-preserving dual interac-tive wasserstein generative adversarial network for cloud-basedroad condition monitoring in vanets,” Applied Soft Computing,vol. 154, p. 111367, 2024.[17] A.Rezaei,M.Sookhak,andA.Patooghy,“Privacy-preservinginconnectedandautonomousvehiclesthroughvisiontotexttransformation,”inProceedingsofthe[ConferenceName],2025.[Online].Available:https://api.semanticscholar.org/CorpusID:279464183[18] T.Sun.(2024)Newtrafficcamerasautomat-icallyblurdrivers’faces—butissueai-poweredticketsanyway.Accessed:2025-04-30.[On-line]. Available: https://www.the-sun.com/motors/13632696/new-traffic-cameras-automatically-blur-drivers-faces/[19] Z. Xiao, J. Lin, J. Chen, H. Fu, Y. Li, J. Yuan, and Z. Li, “Privacypreservation network with global-aware focal loss for interactivepersonal visual privacy preservation,” Neurocomputing, vol. 602,p. 128193, 2024.
[20] C. Xie, Z. Cao, Y. Long, D. Yang, D. Zhao, and B. Li, “Privacyof autonomous vehicles: Risks, protection methods, and futuredirections,” arXiv preprint arXiv:2209.04022, 2022.[21] B. Jiang, B. Bai, H. Lin, Y. Wang, Y. Guo, and L. Fang, “Dart-blur: Privacy preservation with detection artifact suppression,” inProceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, 2023, pp. 16 479–16 488.[22] M. Ye, W. Shen, J. Zhang, Y. Yang, and B. Du, “Securereid:Privacy-preserving anonymization for person re-identification,”IEEE Transactions on Information Forensics and Security,vol. 19, pp. 2840–2853, 2024.[23] L. Song and P. Mittal, “Systematic evaluation of privacy risks ofmachine learning models,” in 30th USENIX security symposium(USENIX security 21), 2021, pp. 2615–2632.[24] Y. Gu, J. He, and K. Chen, “Ft-privacyscore: Personalized privacyscoring service for machine learning participation,” in Proceed-ings of the 2024 on ACM SIGSAC Conference on Computer andCommunications Security, 2024, pp. 5075–5077.",7.97,
